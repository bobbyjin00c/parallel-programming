# 并行程序设计笔记总结

## Chapter2.并行硬件与并行软件

**并发计算**：一个程序的多个任务在同一个时段内可以同时执行
**并行计算**：程序通过多个任务器紧密协作来解决某个问题
**分布式计算**：程序需要与其他程序协作解决某个问题
·并行程序与分布式程序都是并发的

**任务并行**：将待解决问题所需要的各个任务分配到各个核上执行

**数据并行**：将待解决问题所需要处理的数据分配给各个核，每个核在分配到的数据集上执行大致的操作

**冯·诺伊曼结构**：主存、CPU处理器或核、主存与CPU之间的互连结构
·数据/指令传送到CPU，称为：数据从内存中取出/读出
·数据/指令从CPU传送到主存，称为：数据写入/存入内存
**冯·诺伊曼瓶颈**：主存与CPU之间的分离，互连结构限定了指令和数据访问的速率，程序运行所需要的大部分数据与指令被有效地与CPU分隔开

**进程**：运行着的程序的一个实例
**多任务**：操作系统提供对同时运行多个程序的支持
·一个线程开始时，从进程中派生出来，当一个线程结束，合并到进程中

**Cache 缓存**：解决冯诺依曼瓶颈的最广泛使用方法之一
·缓存的访问时间比其他存储区域的访问时间短
**CPU缓存**：相比于主存，CPU能够更快速地访问的内存区域

**局部性**：程序访问完一个内存区域（指令或数据），将在不久的将来（时间局部性）访问邻近的区域（空间局部性）

·时间局部性：一旦某个内存被访问，在不久的将来这个位置很可能被再次访问

·空间局部性：一旦某个内存位置被访问，其附近的内存位置也很可能被访问

·利用局部性原理，系统使用更宽的互连结构访问数据与指令，一次内存访问能存取**一整块**代码和数据，而不是单条指令和数据，这些块称为**高速缓存块/行**

当CPU向Cache中写数据时，Cache中的值与主存中的值会不同或不一致，解决方法：
·**写直达Cache**：当CPU向Cache写数据时，高速缓存行会**立即写入主存**
·**写回Cache**:将发生数据更新的高速缓存块**标记为“脏 dirty”**，当发生高速缓存时标记为脏的高速缓存块被**写入主存中**

**Cache映射**
**全相联Cache**：每个高速缓存行能够放置在Cache中的任意位置
**直接映射Cache**：每个高速缓存行在Cache中有唯一位置
**n路组相连**：（折中）每个高速缓存行能放置在Cache中n个不同位置中的一个
当内存中的行能被映射到Cache中多个不同位置，需要决定替换或者驱逐Cache中的哪一行
常用替换方案：最近最少使用：Cache记录各个块被访问次数替换最近访问最少的块

**虚拟模拟器（虚拟内存）**：内存管理技术，通过将主存与辅助存储结合使用，为每个进程提供独立且扩展的虚拟地址空间
**交换空间**：暂时用不到的部分存储到辅助的块中

**指令级并行**：通过让多个处理器部件或功能单元同时执行指令来提高处理器性能
·流水线：将功能单元分阶段安排 
·多发射：让多条指令同时启动

**多发射指令调度**：编译时：静态多发射；运行时：动态多发射——超标量

**线程级并行**：尝试通过同时执行不同线程来提供并行性，提供粗粒度的并行性
·粗粒度：同时执行的程序基本单元（线程）比细粒度的程序单元（单条指令）更大或更粗
·硬件多线程为系统提供一种机制，是当前执行的任务被阻塞时，系统可以继续其他有用的工作
**细粒度多线程**：处理器在每条指令执行完后切换线程，跳过被阻塞的线程
**粗粒度多线程**：只切换需要等待较长时间才能完成操作而被阻塞的线程
**同步多线程**：细粒度多线程的变种，允许多种多线程同时使用多功能单元来进行超标量处理器的性能

**Flynn分类法**：按照能够同时管理的指令流数目与数据流数目来对系统分类
·典型冯·诺依曼系统是单指令单数据系统（SISD）】
**SIMD**：单指令多数据流，并行系统，通过对多个数据执行相同的指令实现在多个数据流上的操作

·GPU不是存粹SIMD系统，GPU有十几个核，每个核均能独立执行指令流

·SIMD优势：
  可以利用数据集并行
  比MIMD更节能
  允许程序员按顺序思考
  与MIMD相比，SIMD潜在加速是MIMD的两倍

**数据并行**：将数据分配给多个处理器，让各个处理器使用相同的指令来操作数据子集并实现并行化
·SIMD在大型数据并行化上十分有用
**向量处理器**：能够对数组或数据向量进行操作（包括：向量寄存器，向量化和流水化的功能单元，向量指令，交叉存储器，步长式存储器访问和硬件散射/聚集）
·传统CPU对单独的数据元素或标量进行操作

**MIMD**：多指令多数据流：系统支持同时多个指令在多个数据流上操作
·MIMD通常异步，各个处理器可以按照自己的节奏运行

**共享内存系统**：处理器通过互连网络与内存系统相互连接，每个处理器能够访问到每个内存区域，处理器通过访问共享的数据结构隐式通信
**分布式内存系统**：每个处理器都有自己私有的内存空间，处理器之间通过发送消息或者使用特殊函数访问其他处理器内存来显式通信

**Cache一致性**：在多核系统中，每个核的cache存储相同变量副本，当某个处理器更新该cache中的变量副本时，其他处理器也应当知道更新，并更新其cache中对应变量副本
**监听Cache一致性协议**：当多个核共享总线时，总线上的信号都能被连接到总线的所有核“看到”。某个核在更新cache中副本时会将更新信息在总线上广播，如果其他核正在监听总线就会知道信息并将自己的对应副本标记为非法
**基于目录Cache一致性协议**：通过“目录”数据结构来解决互连网络间广播较慢的问题

**伪共享**：发生在多个线程访问不同变量，但这个变量共享同一个缓存行时，尽管这些变量并不相互依赖，但由于其存储位置在缓存中靠得很近，导致处理器频繁无效化缓存行从而影响性能

**SPMD**：单程序多数据流：仅包含一段可执行代码，通过使用条件转移语句让代码在执行时表现得像在不同处理器上执行不同的程序
·SPMD可以实现任务并行性

**负载均衡**：每个线程/进程获得大致相等的工作量
**并行化**：将串行程序或算法转换为并行程序的过程为并行化
**易并行**：可以通过简单的讲任务分配给进程/线程实现并行化
**分布式内存**：每个核可以直接访问自己的私有内存
**竞争条件**：进程或线程尝试同时访问一个资源而引发错误
**临界区**：一次只能被一个线程执行的代码
·在分布式内存程序中，只有进程0可以访问stdin
·在共享内存程序中，只有主线程或线程0可以访问stdin
·所有线程/进程都可以访问stdout核stderr

**性能**：
·加速比：S=T串行/T并行
·效率：E=S/p =（T串行/T并行）/p =T串行/(T并行·p)  // p指核数（p核）
·T并行 = T串行 /p + T开销 //T开销：并行开销，如通信或互斥

**阿姆达尔定律**：大致上，除非一个串行程序的执行几乎全部被并行化，否则无论多少可利用的核，通过并行化产生的加速比都是受限的

·具体来说：如果一个程序有P部分可以并行执行，剩余的1-P部分必须串行处理，那么即使使用无限多的处理器，程序的最大加速比也仅为1/1-P。串行部分是整体性能提升的瓶颈

·局限性：未考虑问题的规模；且实际影响不大（科学家试验正向反馈，小加速比功能强大）

**可扩展性**：对于拥有固定进程或线程数目的并行程序，其数据规模也是固定的，若增加程序所用的线程/进程数，如果在输入规模也以相应增长率增加的情况下，程序的效率一直固定，那么说这个程序可扩展
·强可扩展：增加线程/进程数，可以维持固定效率却不增加问题规模时程序强可扩展
·弱可扩展：增加线程/进程数的同时需要以相同倍率增加问题规模以保持效率值不变

**Foster方法**：划分，通信，凝聚或聚合，分配
·划分：将要执行的指令和数据按照计算部分拆分为多个小任务
·通信：确定上一步所识别出来的任务之间需要执行哪些通信
·聚合：将第一不确定的任务与通信结合为更大的任务
·映射：将上一步聚合好的任务分配到进程/线程中

**进程悬挂**：一个进程试图接收信息，但是没有相匹配的信息，那么该进程会永远阻塞在这里，称为进程悬挂

**线程安全**：如果一个代码块能够被多个线程同时执行而不引起问题，那么它是线程安全的

**路障（barrier）**:线程必须阻塞直到所有线程到达这个节点才能执行，实现同步

### Question
1. SIMD&SIMD:
SIMD: single instruction multiple data 所有处理单元同步执行同一个指令，操作不同数元素，适合规则并行处理
SIMT: single instruction multiple threads 多个线程执行同一指令。每个线程可独立处理不同数据，适合不规则数据并行处理

2. UMA&NUMA
UMA: uniform memory access 一致存储访问系统
NUMA: Non-Uniform memory access 非一致存储访问系统

3. MPP&COW
  MPP: 大规模并行处理器系统
  COW: 工作站集群系统
  **区别**
  【节点独立性】
  MPP:节点高度集成，专为并行计算设计，通常没有独立操作系统，以来全局调度和管理系统
  COW:节点完全独立，各自运行操作系统和应用系统，节点间通过消息传递通信
  【网络连接】
  MPP:使用专用高速互连网络，延迟低，带宽高，适合大规模并行计算
  COW:使用标准网络（以太网等）延迟较高，带宽较低，适合松散耦合任务

4. 互连网络与互联网的区别与联系
  【互连网络】连接多个计算设备或结点的网络，通常用于高性能计算，数据中心等，强调高带宽低延迟
  【互联网】全球范围的公共网络，链接数万个私有和公共网络，使用TCP/IP协议，提供电子邮件，Web浏览等服务
  ·互连网络可以接入互联网，扩展应用服务

5. 等分宽度（bisection width）
  将一个网络分为两个大致相等的部分所需要移除的最小边数
  【意义】影像处理器间的通信效率，宽度越大通信效率越高

6. 路由策略
  cut-through路由策略：数据包在到达中间节点时无需完全接收整个数据包即可开始转发，低延迟，错误传播风险较高
  store-and-forward：传统方式，节点需要接收完整数据包后转发，延迟较高，但可检测并纠正错误

7. SPMD编程模式：多处理器执行相同的程序，通过条件语句执行不同的代码

8. 为何多线程并行程序执行时结果存在不确定性？（Nondeterminism）
   竞争条件(Race condition)：多个线程对共享资源的访问顺序不确定，导致结果依赖于线程执行顺序
   多个线程同时读写共享数据时，如果没有同步机制（锁，信号量等）。可能导致数据不一致

9. 可扩展性：系统网络软件在需求增加时能够通过扩展资源来提升性能和容量的能力
  ·强可扩展：问题规模保持不变的情况下，增加处理器数量算法或系统的执行时间相应减少
  ·弱可扩展：处理器数量增加的同时相应增加问题规模使得每一个处理器处理的数据量大致相同
  【区别】强可扩展固定问题规模，增加处理器数量目标是减少执行时间
        弱可扩展同时增加问题规模与处理器数量，目标是保持或提升每单位时间的计算效率

10. foster方法论：划分 通信 聚合 映射

